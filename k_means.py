# -*- coding: utf-8 -*-
"""k-means.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UnsMtU8bCNYI8PHH6AsF52SNRWRW-e0I

# About this Dataset

The Wholesale Customers dataset contains 440 clients of a Portuguese distributor. Each record shows the customer type (Channel), region, and annual spending on six product categories: Fresh, Milk, Grocery, Frozen, Detergents_Paper, and Delicassen. It is mainly used for clustering and customer segmentation.

# step1 Data Collection

In this step, we import  Libraries and
 load the review dataset  We will first inspect the dataset to understand its structure.
"""

#import Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

#Load Dataset
data=pd.read_csv('/content/Wholesale customers data.csv')

# Check the first few rows
data.head()

data.info()##show num of row , col ,datatype and missing value

data.describe() # show missing value , mean , std ( probablity)

"""# 2.Data Exploration

Before preprocessing, it's important to explore the data. if there are any missing values and check outlier and visualization
"""

data.Region.value_counts()

data.Channel.value_counts()

# Check for missing values
print(data.isnull().sum())

from scipy.stats import zscore

z_scores = (data - data.mean()) / data.std()
outliers = (z_scores.abs() > 3).sum()

print("Number of outliers feature:\n", outliers)

plt.figure(figsize=(8, 4))
plt.boxplot(data['Fresh'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

plt.figure(figsize=(8, 4))
plt.boxplot(data['Milk'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

plt.figure(figsize=(8, 4))
plt.boxplot(data['Grocery'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

plt.figure(figsize=(8, 4))
plt.boxplot(data['Frozen'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

plt.figure(figsize=(8, 4))
plt.boxplot(data['Detergents_Paper'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

plt.figure(figsize=(8, 4))
plt.boxplot(data['Delicassen'], vert=False)  # Use boxplot for outlier visualization
plt.title(f'Boxplot of Outliers')
plt.show()

"""# 3.Data Preprocessing

We clean the data by removing outlier , do standerd scaler and splitting the dataset into training and testing sets.
"""

numeric_cols = data.drop(["Channel", "Region"], axis=1)  #  remove categorical
z_scores = np.abs(zscore(numeric_cols))

# Threshold = 3 any value>3 is outlier
threshold = 3
data_clean= data[(z_scores < threshold).all(axis=1)]

print("Original shape:", data.shape)
print("After removing outliers:", data_clean.shape)

#del outlier using IQR

data_clean = data.copy()
for col in numeric_cols:
    Q1 = data[col].quantile(0.25)
    Q3 = data[col].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    data_clean = data_clean[(data_clean[col] >= lower_bound) & (data_clean[col] <= upper_bound)]

print("Shape after IQR outlier removal:", data_clean.shape)

plt.figure(figsize=(12,6))
sns.boxplot(data=data.drop(["Channel","Region"], axis=1))
plt.title("Before Removing Outliers (IQR)")
plt.show()

plt.figure(figsize=(12,6))
sns.boxplot(data=data_iqr_removed.drop(["Channel","Region"], axis=1))
plt.title("After Removing Outliers (IQR)")
plt.show()

# Scaling
from sklearn.preprocessing import StandardScaler

scaler_Standard = StandardScaler().fit_transform(data)
scaler_Standard[:5]

# Convert the scaled data back to a DataFrame with the same columns
scaled_Standard_data = pd.DataFrame(scaler_Standard, columns=data.columns)

# Now, scaled_df contains the scaled data in the same structure as df
print(scaled_Standard_data.head())

"""# Elbow method for KMeans Clustering"""

from sklearn.cluster import KMeans

# Elbow method
inertia = []
for k in range(2, 19):
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(scaled_Standard_data)
    inertia.append(kmeans.inertia_)

plt.plot(range(2, 19), inertia, marker='o')
plt.xlabel("Number of Clusters (k)")
plt.ylabel("Inertia")
plt.title("Elbow Method")
plt.show()

#choose k=7
kmeans = KMeans(n_clusters=7, random_state=42)
labels = kmeans.fit_predict(scaled_Standard_data)

# Add labels back to dataframe
scaled_Standard_data["Cluster"] = labels

# Visualization (pairplot for first few features)
sns.pairplot(scaled_Standard_data[['Fresh','Milk','Grocery','Cluster']], hue="Cluster", palette="Set2")
plt.show()

from sklearn.metrics import silhouette_score

for k in range(2, 19):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(scaled_Standard_data)
    score = silhouette_score(scaled_Standard_data, labels)
    print(f"k={k}, silhouette score={score:.3f}")

#choose k=9
kmeans = KMeans(n_clusters=9, random_state=42)
labels = kmeans.fit_predict(scaled_Standard_data)

from sklearn.decomposition import PCA

pca = PCA(n_components=2)
X_pca = pca.fit_transform(scaled_Standard_data)

print("Shape after PCA:", X_pca.shape)

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

inertia = []
K = range(2, 11)
for k in K:
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans.fit(X_pca)   # data afer pca
    inertia.append(kmeans.inertia_)

# plot Elbow
plt.figure(figsize=(8,6))
plt.plot(K, inertia, 'bo-')
plt.xlabel("Number of Clusters (k)")
plt.ylabel("Inertia")
plt.title("Elbow Method after PCA")
plt.show()

silhouette_scores = []
for k in range(2, 11):
    kmeans = KMeans(n_clusters=k, random_state=42)
    labels = kmeans.fit_predict(X_pca)
    score = silhouette_score(X_pca, labels)
    silhouette_scores.append((k, score))
    print(f"k={k}, silhouette score={score:.3f}")

kmeans = KMeans(n_clusters=5, random_state=42)
labels = kmeans.fit_predict(X_pca)

# Plot clusters
import matplotlib.pyplot as plt

plt.figure(figsize=(8,6))
plt.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', s=50)
plt.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1],
            c='red', marker='X', s=200, label='Centroids')
plt.title(f"KMeans Clusters (k={5}) after PCA")
plt.legend()
plt.show()

